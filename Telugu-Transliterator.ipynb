{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMy6D1doMng6",
        "outputId": "20d16a2a-4b9a-450b-b98f-8fdcb3e59263"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/CPU:0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import seaborn as sns\n",
        "import os, string, random, time, math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import clear_output\n",
        "import re\n",
        "import string\n",
        "\n",
        "device_gpu = \"/GPU:0\" if tf.config.list_physical_devices('GPU') else \"/CPU:0\"\n",
        "print(device_gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbOzzYMqNtMB",
        "outputId": "c7a09bec-7ffd-4720-85d5-4a721d182f83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available: 0\n",
            "No GPU found.\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(\"GPU Name:\", gpus[0].name)\n",
        "else:\n",
        "    print(\"No GPU found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXor2z4RN6iu"
      },
      "source": [
        "### Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX7iKp5BOLtM",
        "outputId": "55dd0d67-0e0d-4117-910f-9edb1093095e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, '^': 1, '$': 2, 'A': 3, 'B': 4, 'C': 5, 'D': 6, 'E': 7, 'F': 8, 'G': 9, 'H': 10, 'I': 11, 'J': 12, 'K': 13, 'L': 14, 'M': 15, 'N': 16, 'O': 17, 'P': 18, 'Q': 19, 'R': 20, 'S': 21, 'T': 22, 'U': 23, 'V': 24, 'W': 25, 'X': 26, 'Y': 27, 'Z': 28}\n"
          ]
        }
      ],
      "source": [
        "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "pad = '-PAD-'\n",
        "sos = '^'\n",
        "eos = '$'\n",
        "engdic = {pad: 0, sos: 1, eos: 2}\n",
        "for index ,alpha in enumerate(eng_alphabets):\n",
        "  engdic[alpha] = index+3\n",
        "print(engdic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVzp945kOOZV",
        "outputId": "10d1a104-b481-4edf-b7de-827680df5cfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ఀ': 1, 'ఁ': 2, 'ం': 3, 'ః': 4, 'ఄ': 5, 'అ': 6, 'ఆ': 7, 'ఇ': 8, 'ఈ': 9, 'ఉ': 10, 'ఊ': 11, 'ఋ': 12, 'ఌ': 13, '\\u0c0d': 14, 'ఎ': 15, 'ఏ': 16, 'ఐ': 17, '\\u0c11': 18, 'ఒ': 19, 'ఓ': 20, 'ఔ': 21, 'క': 22, 'ఖ': 23, 'గ': 24, 'ఘ': 25, 'ఙ': 26, 'చ': 27, 'ఛ': 28, 'జ': 29, 'ఝ': 30, 'ఞ': 31, 'ట': 32, 'ఠ': 33, 'డ': 34, 'ఢ': 35, 'ణ': 36, 'త': 37, 'థ': 38, 'ద': 39, 'ధ': 40, 'న': 41, '\\u0c29': 42, 'ప': 43, 'ఫ': 44, 'బ': 45, 'భ': 46, 'మ': 47, 'య': 48, 'ర': 49, 'ఱ': 50, 'ల': 51, 'ళ': 52, 'ఴ': 53, 'వ': 54, 'శ': 55, 'ష': 56, 'స': 57, 'హ': 58, '\\u0c3a': 59, '\\u0c3b': 60, '఼': 61, 'ఽ': 62, 'ా': 63, 'ి': 64, 'ీ': 65, 'ు': 66, 'ూ': 67, 'ృ': 68, 'ౄ': 69, '\\u0c45': 70, 'ె': 71, 'ే': 72, 'ై': 73, '\\u0c49': 74, 'ొ': 75, 'ో': 76, 'ౌ': 77, '్': 78, '\\u0c4e': 79, '\\u0c4f': 80, '\\u0c50': 81, '\\u0c51': 82, '\\u0c52': 83, '\\u0c53': 84, '\\u0c54': 85, 'ౕ': 86, 'ౖ': 87, '\\u0c57': 88, 'ౘ': 89, 'ౙ': 90, 'ౚ': 91, '\\u0c5b': 92, '\\u0c5c': 93, 'ౝ': 94, '\\u0c5e': 95, '\\u0c5f': 96, 'ౠ': 97, 'ౡ': 98, 'ౢ': 99, 'ౣ': 100, '\\u0c64': 101, '\\u0c65': 102, '౦': 103, '౧': 104, '౨': 105, '౩': 106, '౪': 107, '౫': 108, '౬': 109, '౭': 110, '౮': 111, '౯': 112, '\\u0c70': 113, '\\u0c71': 114, '\\u0c72': 115, '\\u0c73': 116, '\\u0c74': 117, '\\u0c75': 118, '\\u0c76': 119, '౷': 120, '౸': 121, '౹': 122, '౺': 123, '౻': 124, '౼': 125, '౽': 126, '౾': 127, '\\u200c': 128, '\\u200d': 129}\n"
          ]
        }
      ],
      "source": [
        "#Telugu unicode for hex range is 3072:3199\n",
        "tel_alphabets = [chr(alpha) for alpha in range(3072,3199)]\n",
        "tel_alphabets.append(chr(8204))\n",
        "tel_alphabets.append(chr(8205))\n",
        "tel_size = len(tel_alphabets)\n",
        "teldic = {pad : 0}\n",
        "for index ,alpha in enumerate(tel_alphabets):\n",
        "  teldic[alpha] = index+1\n",
        "print(teldic)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQ5Vr9F9OZuQ",
        "outputId": "1677c144-c1ad-4833-aad4-e2adb21b65cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ఆం\n"
          ]
        }
      ],
      "source": [
        "print(tel_alphabets[6]+tel_alphabets[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyWbo3w4OdMS"
      },
      "source": [
        "### preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "QrTfMlXPOjnu"
      },
      "outputs": [],
      "source": [
        "X=[]\n",
        "Y=[]\n",
        "with open(r\"EngToTel.txt\",encoding = \"utf8\") as f:\n",
        "  for line in f:\n",
        "    line = line.split()\n",
        "    eng = line[0].strip().upper()\n",
        "    tel = line[1].strip()\n",
        "    X.append(eng)\n",
        "    Y.append(tel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwQQQZM7PNaQ",
        "outputId": "df16d58e-6948-476a-a00c-9a849b745339"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEVATA\n",
            "దేవత\n"
          ]
        }
      ],
      "source": [
        "print(X[1])\n",
        "print(Y[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "b9Z1WMaGPe8k"
      },
      "outputs": [],
      "source": [
        "def checkAdjChar(instring):\n",
        "    for i in range(0, len(instring)-2):\n",
        "        if (instring[i] == instring[i+1]):\n",
        "            return 1\n",
        "        else:\n",
        "            continue\n",
        "    return 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "-1oZice4QTlC"
      },
      "outputs": [],
      "source": [
        "L=[]\n",
        "M=[]\n",
        "with open(r\"TelToEng.txt\",encoding = \"utf8\") as k:\n",
        "    for line in k:\n",
        "        line = line.split()\n",
        "        EN = line[1].strip().upper()\n",
        "        TE = line[0].strip()\n",
        "        if(len(TE)>10 and checkAdjChar(EN)==0):\n",
        "            L.append(EN)\n",
        "            M.append(TE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydMVRvFCQcdz",
        "outputId": "4fdb6dd6-5e07-49d5-dc6b-b00a1a0697fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANUMATINCHALEDU\n",
            "అనుమతించలేదు\n"
          ]
        }
      ],
      "source": [
        "print(L[5])\n",
        "print(M[5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Ioz29g9qROQF"
      },
      "outputs": [],
      "source": [
        "X = X+L\n",
        "Y = Y+M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "VLAVfEYf1oJ-"
      },
      "outputs": [],
      "source": [
        "\n",
        "X=[f\"^{word.upper()}$\" for word in X]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKDgNEAO2Gu1",
        "outputId": "4c8eae04-42bd-4fb8-c023-5a033c0a63ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^DEVATA$\n"
          ]
        }
      ],
      "source": [
        "print(X[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amPuM0XwRZZJ",
        "outputId": "e2bf4093-12dc-485c-c4e9-f5c10ce637c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16026\n"
          ]
        }
      ],
      "source": [
        "print(len(X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "fvC3OfZPRQBF"
      },
      "outputs": [],
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Awen3MIrRfOE",
        "outputId": "b5804926-174f-4970-f59e-78b97355142c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training size: 12820\n",
            "Test size: 3206\n"
          ]
        }
      ],
      "source": [
        "print(f\"Training size:\",len(X_train))\n",
        "print(f\"Test size:\",len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeiQcks2RURD",
        "outputId": "83a8b8dc-ce93-4e64-b199-1ec075fad8ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^MANIK$ మాణిక్\n",
            "^ASIMA$ అసీమా\n",
            "^HALEEM$ హలీమ్\n"
          ]
        }
      ],
      "source": [
        "for i in range(3):\n",
        "  print(X_train[i],Y_train[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2RiLJOCSIQ4"
      },
      "source": [
        "### **dataloading**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PydBxAE9LqgJ"
      },
      "outputs": [],
      "source": [
        "class TFDataloader:\n",
        "    def __init__(self, a, b):\n",
        "        self.tel_words, self.eng_words = a, b\n",
        "        self.shuffle_indices = list(range(len(self.tel_words)))\n",
        "        random.shuffle(self.shuffle_indices)\n",
        "        self.shuffle_start_index = 0\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tel_words)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.tel_words[idx], self.eng_words[idx]\n",
        "\n",
        "    def get_random_sample(self):\n",
        "        idx = np.random.randint(len(self.tel_words))\n",
        "        return self.__getitem__(idx)\n",
        "\n",
        "    def get_batch_from_array(self, batch_size, array):\n",
        "        end = self.shuffle_start_index + batch_size\n",
        "        batch = []\n",
        "        if end >= len(self.tel_words):\n",
        "            batch = [array[i] for i in self.shuffle_indices[0:end % len(self.tel_words)]]\n",
        "            end = len(self.tel_words)\n",
        "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index:end]]\n",
        "\n",
        "    def get_batch(self, batch_size, postprocess=True):\n",
        "        tel_batch = self.get_batch_from_array(batch_size, self.tel_words)\n",
        "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
        "        self.shuffle_start_index += batch_size\n",
        "\n",
        "        if self.shuffle_start_index >= len(self.tel_words):\n",
        "            random.shuffle(self.shuffle_indices)\n",
        "            self.shuffle_start_index = 0\n",
        "\n",
        "        return tel_batch, eng_batch\n",
        "\n",
        "    def to_tf_dataset(self, batch_size):\n",
        "\n",
        "        def batch_generator():\n",
        "            while True:\n",
        "                tel_batch, eng_batch = self.get_batch(batch_size)\n",
        "                for tel, eng in zip(tel_batch, eng_batch):\n",
        "                    yield tel, eng\n",
        "\n",
        "        dataset = tf.data.Dataset.from_generator(\n",
        "            batch_generator,\n",
        "            output_signature=(\n",
        "                tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "                tf.TensorSpec(shape=(), dtype=tf.string)\n",
        "            )\n",
        "        )\n",
        "        return dataset.batch(batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8yWUbijSMUa",
        "outputId": "3d4ad418-cd05-46e6-d2b7-408dad4953a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class '__main__.TFDataloader'>\n",
            "('ప్రోటిస్టా', '^PROTIST$')\n",
            "('శాండ్\\u200cవిచ్', '^SANDWICH$')\n",
            "('కపూర్', '^KAPOOR$')\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_data = TFDataloader(Y_train, X_train)\n",
        "test_data = TFDataloader(Y_test, X_test)\n",
        "\n",
        "print(type(test_data))\n",
        "\n",
        "for i in range(3):\n",
        "    print(test_data[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loFOSXWQSZTv",
        "outputId": "b921c6f8-49e7-4d54-dd85-c7ce3e7369a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(['చోలా', 'శోభా', 'వెస్టిండీస్తో', 'మేర్లపాక', 'టాగూర్', 'పొట్లదుర్తి', 'ప్రధాన', 'ఇద్దరమ్మాయిలతో', 'రౌలింగ్', 'సుబ్రహ్మణ్య'], ['^CHOLA$', '^SOBHA$', '^WESTINDESTHO$', '^MERLAPAKA$', '^TAGORE$', '^POTLADURTHI$', '^PRADHAN$', '^IDDARAMMAYILATHO$', '^ROWLING$', '^SUBRAMANYA$'])\n"
          ]
        }
      ],
      "source": [
        "bss=train_data.get_batch(10)\n",
        "print(bss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "RI91aUu2S1Wz"
      },
      "outputs": [],
      "source": [
        "def word_rep_tf(word, dic):\n",
        "    word = word.upper()\n",
        "    vocab_size = len(dic)\n",
        "    seq_len = len(word) + 1\n",
        "    one_hot = tf.zeros((seq_len, vocab_size), dtype=tf.float32)\n",
        "\n",
        "    for i, letter in enumerate(word):\n",
        "        pos = dic[letter]\n",
        "        one_hot = tf.tensor_scatter_nd_update(one_hot, [[i, pos]], [1.0])\n",
        "\n",
        "    pad_pos = dic[pad]\n",
        "    one_hot = tf.tensor_scatter_nd_update(one_hot, [[len(word), pad_pos]], [1.0])\n",
        "    return tf.expand_dims(one_hot, axis=0)  # Shape: (1, seq_len, vocab_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "SfTeEQ_2S5En"
      },
      "outputs": [],
      "source": [
        "def gt_rep(word, dic, device='/CPU:0'):\n",
        "    word = word.upper()\n",
        "    with tf.device(device):\n",
        "        rep = tf.zeros([len(word) + 1, 1], dtype=tf.int64)\n",
        "\n",
        "        indices = []\n",
        "        updates = []\n",
        "\n",
        "        for letter_index, letter in enumerate(word):\n",
        "            pos = dic[letter]\n",
        "            indices.append([letter_index, 0])\n",
        "            updates.append(pos)\n",
        "\n",
        "        # Add padding at the end\n",
        "        indices.append([len(word), 0])\n",
        "        updates.append(dic[pad])\n",
        "\n",
        "        rep = tf.tensor_scatter_nd_update(rep, indices=indices, updates=updates)\n",
        "        rep = tf.reshape(rep, (1, -1))\n",
        "\n",
        "    return rep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg9lxjqeTCU5",
        "outputId": "2730868c-caa2-4fe6-ec8e-393e723c6f7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "పంజాబీ\n",
            "దేవత\n",
            "బెషెవిస్\n"
          ]
        }
      ],
      "source": [
        "for i in range(3):\n",
        "    print(Y[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJ0RnftSMtUd",
        "outputId": "48a0d3b5-bf20-49b1-b8c3-d9450045a776"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 7, 130)\n"
          ]
        }
      ],
      "source": [
        "a=word_rep_tf(Y[0],teldic)\n",
        "\n",
        "print(a.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udoMhi-NYpKH",
        "outputId": "9bd46d96-2515-4e9e-875f-012979e16c17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "చన్నపట్న ^CHANNAPATNA$\n",
            "(1, 9, 130)\n",
            "(1, 14)\n",
            "పెర్సల్ఫేట్ ^PERSULFATE$\n",
            "(1, 12, 130)\n",
            "(1, 13)\n",
            "నాగార్జున ^NAGARJUN$\n",
            "(1, 10, 130)\n",
            "(1, 11)\n",
            "రీమాన్ ^RIEMANN$\n",
            "(1, 7, 130)\n",
            "(1, 10)\n",
            "భార్గవి ^BHARGAVI$\n",
            "(1, 8, 130)\n",
            "(1, 11)\n",
            "వాసుదేవ్ ^VASUDEV$\n",
            "(1, 9, 130)\n",
            "(1, 10)\n",
            "దిగువమాసపల్లె ^DIGUVAMASAPALLE$\n",
            "(1, 14, 130)\n",
            "(1, 18)\n",
            "డికెన్స్ ^DICKENS$\n",
            "(1, 9, 130)\n",
            "(1, 10)\n",
            "కార్డ్ ^CARD$\n",
            "(1, 7, 130)\n",
            "(1, 7)\n",
            "కమ్యూనిటీ ^COMMUNITY$\n",
            "(1, 10, 130)\n",
            "(1, 12)\n",
            "నందవరం ^NANDAVARAM$\n",
            "(1, 7, 130)\n",
            "(1, 13)\n",
            "కోయాజీ ^COYAJI$\n",
            "(1, 7, 130)\n",
            "(1, 9)\n",
            "లక్సెట్టిపేట ^LUXETTIPET$\n",
            "(1, 13, 130)\n",
            "(1, 13)\n",
            "హలా ^HALA$\n",
            "(1, 4, 130)\n",
            "(1, 7)\n",
            "వికీబుక్స్ ^WIKIBOOKS$\n",
            "(1, 11, 130)\n",
            "(1, 12)\n",
            "సార్కాప్టిస్ ^SARCOPTES$\n",
            "(1, 13, 130)\n",
            "(1, 12)\n",
            "మోర్స్ ^MORSE$\n",
            "(1, 7, 130)\n",
            "(1, 8)\n",
            "అంటోన్ ^ANTON$\n",
            "(1, 7, 130)\n",
            "(1, 8)\n",
            "నరనారాయణులు ^NARANARAYANA$\n",
            "(1, 12, 130)\n",
            "(1, 15)\n",
            "స్వర్ణమాల్య ^SWARNAMALYA$\n",
            "(1, 12, 130)\n",
            "(1, 14)\n",
            "ముంగిస ^MONGOOSE$\n",
            "(1, 7, 130)\n",
            "(1, 11)\n",
            "పుదుచ్చేరి ^PUDUCHERRY$\n",
            "(1, 11, 130)\n",
            "(1, 13)\n",
            "దీవించండి ^DEEVINCHANDI$\n",
            "(1, 10, 130)\n",
            "(1, 15)\n",
            "నాటింగ్‌హామ్ ^NOTTINGHAM$\n",
            "(1, 13, 130)\n",
            "(1, 13)\n",
            "స్మార్ట్స్పేస్స్ ^SMARTSPACES$\n",
            "(1, 17, 130)\n",
            "(1, 14)\n",
            "చౌక్ ^CHOWK$\n",
            "(1, 5, 130)\n",
            "(1, 8)\n",
            "క్షత్రియ ^KSHATRIYA$\n",
            "(1, 9, 130)\n",
            "(1, 12)\n",
            "భీమ్ ^BHEEM$\n",
            "(1, 5, 130)\n",
            "(1, 8)\n",
            "అంతమవుతుంది ^ANTAMAVUTONDI$\n",
            "(1, 12, 130)\n",
            "(1, 16)\n",
            "పుల్వామా ^PULWAMA$\n",
            "(1, 9, 130)\n",
            "(1, 10)\n",
            "సమాజం ^SAMAJ$\n",
            "(1, 6, 130)\n",
            "(1, 8)\n",
            "చెముడు ^CHEMUDU$\n",
            "(1, 7, 130)\n",
            "(1, 10)\n"
          ]
        }
      ],
      "source": [
        "tel_batch, eng_batch = train_data.get_batch(32)\n",
        "for i in range(len(tel_batch)):\n",
        "  print(tel_batch[i],eng_batch[i])\n",
        "  input_seq = word_rep_tf(tel_batch[i], teldic)  # shape: (1, seq_len, tel_vocab_size)\n",
        "  gt_seq = gt_rep(eng_batch[i], engdic)\n",
        "  print(input_seq.shape)\n",
        "  print(gt_seq.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4O74rUiTOdy",
        "outputId": "6a19398e-f488-45c4-c1bd-84f85fc83c80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^PUNJABI$\n",
            "tf.Tensor([[ 1 18 23 16 12  3  4 11  2  0]], shape=(1, 10), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "sample2 = gt_rep(X[0],engdic)\n",
        "print(X[0])\n",
        "print(sample2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxnoYqw2TVlq"
      },
      "source": [
        "### **GRU With Attention**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpk8OeJMTaKh"
      },
      "outputs": [],
      "source": [
        "class TransliterationEncoderDecoder(tf.keras.Model):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(TransliterationEncoderDecoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.encoder_rnn_cell = tf.keras.layers.GRU(hidden_size, return_sequences=True, return_state=True)\n",
        "        self.decoder_rnn_cell = tf.keras.layers.GRU(hidden_size, return_state=True)\n",
        "\n",
        "        self.h2o = tf.keras.layers.Dense(output_size, activation='softmax')\n",
        "        self.U = tf.keras.layers.Dense(hidden_size)\n",
        "        self.W = tf.keras.layers.Dense(hidden_size)\n",
        "        self.attn = tf.keras.layers.Dense(1)\n",
        "        self.out2hidden = tf.keras.layers.Dense(hidden_size)\n",
        "\n",
        "    def call(self, input_, max_char=30, gt=None,training=True):\n",
        "        batch_size = tf.shape(input_)[0]\n",
        "        eout, hidden = self.encoder_rnn_cell(input_)\n",
        "        decoder_state = hidden\n",
        "        decoder_state = tf.reshape(decoder_state, (1,-1))\n",
        "        decoder_input = tf.zeros((batch_size, 1, self.output_size)) \n",
        "        outputs = []\n",
        "        U = self.U(eout)\n",
        "        for i in range(max_char):\n",
        "            W = self.W(decoder_state)\n",
        "            W = tf.expand_dims(W, 1)\n",
        "            attn_input = tf.nn.tanh(U + W)\n",
        "            V = self.attn(attn_input)\n",
        "            attn_weights = tf.nn.softmax(V, axis=1)\n",
        "            attn_applied = tf.reduce_sum(attn_weights * eout, axis=1, keepdims=True)\n",
        "            embedded = self.out2hidden(decoder_input)\n",
        "            decoder_input_concat = tf.concat([embedded, attn_applied], axis=-1)\n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input_concat, initial_state=decoder_state)\n",
        "            decoder_state = tf.reshape(decoder_state, (1,-1))\n",
        "            out = self.h2o(tf.expand_dims(out, axis=1))\n",
        "            outputs.append(out[:, 0, :])\n",
        "            idx = tf.argmax(out, axis=2, output_type=tf.int32)\n",
        "\n",
        "            if training and gt is not None:\n",
        "                idx = tf.expand_dims(gt[:, i], axis=1)\n",
        "            one_hot = tf.one_hot(idx, depth=self.output_size)\n",
        "\n",
        "            decoder_input = tf.stop_gradient(one_hot)\n",
        "\n",
        "        final_output = tf.stack(outputs, axis=1)\n",
        "        return final_output\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "tURA_UluXoEw"
      },
      "outputs": [],
      "source": [
        "net = TransliterationEncoderDecoder(len(teldic),256,len(engdic))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVf67QOaTwGg"
      },
      "outputs": [],
      "source": [
        "def infer(model, name, n, device='/CPU:0'):\n",
        "    with tf.device(device):\n",
        "        name_ohe = word_rep_tf(name, teldic)\n",
        "        output_batch = model(name_ohe, max_char=n,training=False)\n",
        "        output_single = output_batch[:, 0, :]\n",
        "\n",
        "        return output_single"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtVjLTNwUUi_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxM5n8mq7EDJ"
      },
      "source": [
        "### **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxzW0S2G7Hlq"
      },
      "outputs": [],
      "source": [
        "def train_batch_tf(model, optimizer, loss_fn, tel_batch, eng_batch, teldic, engdic, max_char, device=\"/CPU:0\"):\n",
        "    with tf.device(device):\n",
        "        batch_size = len(tel_batch)\n",
        "        total_loss = 0\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            input_seq = word_rep_tf(tel_batch[i], teldic)  \n",
        "            gt_seq = gt_rep(eng_batch[i], engdic)\n",
        "            gt_without_squeze=gt_seq     \n",
        "            gt_seq = tf.squeeze(gt_seq, axis=0)  \n",
        "            max_char = tf.shape(gt_seq)[0]\n",
        "            with tf.GradientTape() as tape:\n",
        "                output = model(input_seq, max_char=max_char,gt=gt_without_squeze)  \n",
        "                output = output[0]  \n",
        "\n",
        "                loss = 0\n",
        "\n",
        "                for t in range(tf.shape(gt_seq)[0]):\n",
        "                    token_loss = loss_fn(gt_seq[t], output[t])  \n",
        "                    loss += token_loss\n",
        "                loss = loss / tf.cast(tf.shape(gt_seq)[0], tf.float32)\n",
        "            grads = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "            total_loss += loss.numpy()\n",
        "\n",
        "        return total_loss / batch_size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0h5fDcYL7_oJ"
      },
      "outputs": [],
      "source": [
        "def train_setup_tf(model, optimizer, loss_fn, dataset, teldic, engdic, n_batches=100, batch_size=10, max_char=20, device=\"/CPU:0\"):\n",
        "    loss_arr = []\n",
        "\n",
        "    for i in range(n_batches):\n",
        "        tel_batch, eng_batch = dataset.get_batch(batch_size)\n",
        "        loss = train_batch_tf(model, optimizer, loss_fn, tel_batch, eng_batch, teldic, engdic, max_char, device=device)\n",
        "        loss_arr.append(loss)\n",
        "\n",
        "        if True:\n",
        "            print(f\"Iteration {i}, Loss: {loss:.4f}\")\n",
        "            plt.plot(loss_arr, '-*')\n",
        "            plt.xlabel(\"Iteration\")\n",
        "            plt.ylabel(\"Loss\")\n",
        "            plt.show()\n",
        "            clear_output(wait=True)\n",
        "\n",
        "    return loss_arr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VKkMKAmWqBp"
      },
      "outputs": [],
      "source": [
        "def calc_accuracy_tf(model, device='/CPU:0'):\n",
        "    predictions = []\n",
        "    accuracy = 0.0\n",
        "\n",
        "    with tf.device(device):\n",
        "        for i in range(len(test_data)):\n",
        "            tel, eng = test_data[i]\n",
        "            gt = gt_rep(eng, engdic, device)  \n",
        "\n",
        "            outputs = infer(model, tel, gt.shape[0], device=device)  \n",
        "            correct = 0\n",
        "\n",
        "            for index, out in enumerate(outputs):\n",
        "                pred_index = tf.argmax(out, axis=-1).numpy().flatten()[0]  \n",
        "                true_index = gt[index][0].numpy()                   \n",
        "\n",
        "                if pred_index == true_index:\n",
        "                    correct += 1\n",
        "\n",
        "            accuracy += correct / gt.shape[0]\n",
        "\n",
        "        accuracy /= len(test_data)\n",
        "        accuracy *= 100\n",
        "\n",
        "        print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "        return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "JfLV7x6gWtGk"
      },
      "outputs": [],
      "source": [
        "model = TransliterationEncoderDecoder(len(teldic), 256, len(engdic))\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False,reduction=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "collapsed": true,
        "id": "W9NmWUwSsdxU",
        "outputId": "f31fdd46-3647-409a-cf7b-52de9932d8aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[np.float32(2.9453077),\n",
              " np.float32(2.3512027),\n",
              " np.float32(2.3141294),\n",
              " np.float32(2.198294),\n",
              " np.float32(2.1011286),\n",
              " np.float32(2.0488281),\n",
              " np.float32(2.0700438),\n",
              " np.float32(1.9600104),\n",
              " np.float32(2.051372),\n",
              " np.float32(1.8274007),\n",
              " np.float32(2.0758634),\n",
              " np.float32(1.9404002),\n",
              " np.float32(1.8915738),\n",
              " np.float32(1.9109582),\n",
              " np.float32(1.7674453),\n",
              " np.float32(1.8158103),\n",
              " np.float32(1.8656394),\n",
              " np.float32(1.8245964),\n",
              " np.float32(1.7501571),\n",
              " np.float32(1.7516897),\n",
              " np.float32(1.6109655),\n",
              " np.float32(1.5609055),\n",
              " np.float32(1.5220327),\n",
              " np.float32(1.399371),\n",
              " np.float32(1.3807149),\n",
              " np.float32(1.3769822),\n",
              " np.float32(1.3955262),\n",
              " np.float32(1.3125676),\n",
              " np.float32(1.2005231),\n",
              " np.float32(1.3395296),\n",
              " np.float32(1.2318592),\n",
              " np.float32(1.2110763),\n",
              " np.float32(1.1712166),\n",
              " np.float32(1.0331424),\n",
              " np.float32(1.1416045),\n",
              " np.float32(1.0275171),\n",
              " np.float32(1.0712314),\n",
              " np.float32(0.9587411),\n",
              " np.float32(1.0150607),\n",
              " np.float32(0.87555575),\n",
              " np.float32(0.8199854),\n",
              " np.float32(0.9151304),\n",
              " np.float32(0.86082476),\n",
              " np.float32(1.03309),\n",
              " np.float32(0.8789461),\n",
              " np.float32(0.85759836),\n",
              " np.float32(1.0677551),\n",
              " np.float32(0.8961738),\n",
              " np.float32(0.84146726),\n",
              " np.float32(0.88243824),\n",
              " np.float32(0.80990976),\n",
              " np.float32(0.81471354),\n",
              " np.float32(0.8959333),\n",
              " np.float32(0.7790646),\n",
              " np.float32(0.6331694),\n",
              " np.float32(0.84722143),\n",
              " np.float32(0.6182195),\n",
              " np.float32(0.9299657),\n",
              " np.float32(0.8612364),\n",
              " np.float32(0.83921075),\n",
              " np.float32(0.6991101),\n",
              " np.float32(0.75912225),\n",
              " np.float32(0.771386),\n",
              " np.float32(0.735338),\n",
              " np.float32(0.7256159),\n",
              " np.float32(0.5125159),\n",
              " np.float32(0.77781844),\n",
              " np.float32(0.72026813),\n",
              " np.float32(0.7964331),\n",
              " np.float32(0.61075807),\n",
              " np.float32(0.63614213),\n",
              " np.float32(0.5715668),\n",
              " np.float32(0.7919803),\n",
              " np.float32(0.52672386),\n",
              " np.float32(0.90225923),\n",
              " np.float32(0.71387225),\n",
              " np.float32(0.7891364),\n",
              " np.float32(0.70057577),\n",
              " np.float32(0.6761632),\n",
              " np.float32(0.69686675),\n",
              " np.float32(0.8013195),\n",
              " np.float32(0.7977935),\n",
              " np.float32(0.6640261),\n",
              " np.float32(0.60877734),\n",
              " np.float32(0.70286787),\n",
              " np.float32(0.70388204),\n",
              " np.float32(0.7261765),\n",
              " np.float32(0.63341826),\n",
              " np.float32(0.4986549),\n",
              " np.float32(0.67146635),\n",
              " np.float32(0.8180284),\n",
              " np.float32(0.5636219),\n",
              " np.float32(0.4523327),\n",
              " np.float32(0.45183557),\n",
              " np.float32(0.8597141),\n",
              " np.float32(0.49506697),\n",
              " np.float32(0.68351036),\n",
              " np.float32(0.53272337),\n",
              " np.float32(0.62946486),\n",
              " np.float32(0.6649156),\n",
              " np.float32(0.51775473),\n",
              " np.float32(0.65282553),\n",
              " np.float32(0.6017553),\n",
              " np.float32(0.41795927),\n",
              " np.float32(0.7013027),\n",
              " np.float32(0.7384107),\n",
              " np.float32(0.5364233),\n",
              " np.float32(0.5043236),\n",
              " np.float32(0.65585345),\n",
              " np.float32(0.5588285),\n",
              " np.float32(0.6696307),\n",
              " np.float32(0.58106005),\n",
              " np.float32(0.61709684),\n",
              " np.float32(0.4635351),\n",
              " np.float32(0.49743623),\n",
              " np.float32(0.52556413),\n",
              " np.float32(0.5914402),\n",
              " np.float32(0.4764297),\n",
              " np.float32(0.46327615),\n",
              " np.float32(0.5772151),\n",
              " np.float32(0.5224584),\n",
              " np.float32(0.5954621),\n",
              " np.float32(0.52898335),\n",
              " np.float32(0.5301942),\n",
              " np.float32(0.720414),\n",
              " np.float32(0.44794908),\n",
              " np.float32(0.47978127),\n",
              " np.float32(0.46434683),\n",
              " np.float32(0.31542227),\n",
              " np.float32(0.73411894),\n",
              " np.float32(0.6070957),\n",
              " np.float32(0.52869797),\n",
              " np.float32(0.7162621),\n",
              " np.float32(0.73401254),\n",
              " np.float32(0.5223896),\n",
              " np.float32(0.6129989),\n",
              " np.float32(0.4737713),\n",
              " np.float32(0.57656324),\n",
              " np.float32(0.6038558),\n",
              " np.float32(0.38833973),\n",
              " np.float32(0.56969535),\n",
              " np.float32(0.57441765),\n",
              " np.float32(0.37083817),\n",
              " np.float32(0.5122929),\n",
              " np.float32(0.3806641),\n",
              " np.float32(0.54606885),\n",
              " np.float32(0.4443633),\n",
              " np.float32(0.40217096),\n",
              " np.float32(0.3247355),\n",
              " np.float32(0.6078513),\n",
              " np.float32(0.35139745),\n",
              " np.float32(0.56782037),\n",
              " np.float32(0.50450456),\n",
              " np.float32(0.5884808),\n",
              " np.float32(0.5606444),\n",
              " np.float32(0.78591347),\n",
              " np.float32(0.49780235),\n",
              " np.float32(0.6310764),\n",
              " np.float32(0.65246457),\n",
              " np.float32(0.4718053),\n",
              " np.float32(0.4125267),\n",
              " np.float32(0.42325824),\n",
              " np.float32(0.35061303),\n",
              " np.float32(0.44573814),\n",
              " np.float32(0.5744368),\n",
              " np.float32(0.5145908),\n",
              " np.float32(0.47100112),\n",
              " np.float32(0.39193538),\n",
              " np.float32(0.6434779),\n",
              " np.float32(0.55883414),\n",
              " np.float32(0.6254344),\n",
              " np.float32(0.5329026),\n",
              " np.float32(0.5746923),\n",
              " np.float32(0.47934142),\n",
              " np.float32(0.5041598),\n",
              " np.float32(0.5813456),\n",
              " np.float32(0.4376417),\n",
              " np.float32(0.45629755),\n",
              " np.float32(0.3508955),\n",
              " np.float32(0.45527548),\n",
              " np.float32(0.33950043),\n",
              " np.float32(0.33735934),\n",
              " np.float32(0.55845004),\n",
              " np.float32(0.5164719),\n",
              " np.float32(0.45299762),\n",
              " np.float32(0.495416),\n",
              " np.float32(0.46982625),\n",
              " np.float32(0.50224626),\n",
              " np.float32(0.5758518),\n",
              " np.float32(0.44164014),\n",
              " np.float32(0.4773599),\n",
              " np.float32(0.56978357),\n",
              " np.float32(0.4141983),\n",
              " np.float32(0.5158799),\n",
              " np.float32(0.3606585),\n",
              " np.float32(0.5090726),\n",
              " np.float32(0.29638338),\n",
              " np.float32(0.52387637),\n",
              " np.float32(0.5179858),\n",
              " np.float32(0.58554995),\n",
              " np.float32(0.46319118),\n",
              " np.float32(0.5405899),\n",
              " np.float32(0.51053184),\n",
              " np.float32(0.41900298),\n",
              " np.float32(0.5332742),\n",
              " np.float32(0.6119577),\n",
              " np.float32(0.5881066),\n",
              " np.float32(0.62101656),\n",
              " np.float32(0.48895618),\n",
              " np.float32(0.6296577),\n",
              " np.float32(0.4577302),\n",
              " np.float32(0.443138),\n",
              " np.float32(0.4355588),\n",
              " np.float32(0.47672346),\n",
              " np.float32(0.3268761),\n",
              " np.float32(0.47830874),\n",
              " np.float32(0.46075952),\n",
              " np.float32(0.29527226),\n",
              " np.float32(0.40541536),\n",
              " np.float32(0.38483515),\n",
              " np.float32(0.4570748),\n",
              " np.float32(0.39269945),\n",
              " np.float32(0.61414593),\n",
              " np.float32(0.39235318),\n",
              " np.float32(0.40592384),\n",
              " np.float32(0.53811455),\n",
              " np.float32(0.49051207),\n",
              " np.float32(0.42136824),\n",
              " np.float32(0.42599025),\n",
              " np.float32(0.2760838),\n",
              " np.float32(0.4912189),\n",
              " np.float32(0.43212155),\n",
              " np.float32(0.5104304),\n",
              " np.float32(0.43718868),\n",
              " np.float32(0.35408023),\n",
              " np.float32(0.40159747),\n",
              " np.float32(0.46509323),\n",
              " np.float32(0.46329162),\n",
              " np.float32(0.45425293),\n",
              " np.float32(0.54448116),\n",
              " np.float32(0.4150622),\n",
              " np.float32(0.59830767),\n",
              " np.float32(0.3868828),\n",
              " np.float32(0.43114427),\n",
              " np.float32(0.41865623),\n",
              " np.float32(0.6513922),\n",
              " np.float32(0.44456682),\n",
              " np.float32(0.37417072),\n",
              " np.float32(0.65944016),\n",
              " np.float32(0.46228385),\n",
              " np.float32(0.41654843),\n",
              " np.float32(0.42777345),\n",
              " np.float32(0.43521255),\n",
              " np.float32(0.41843936),\n",
              " np.float32(0.51194876),\n",
              " np.float32(0.4500296),\n",
              " np.float32(0.49358594),\n",
              " np.float32(0.47752073),\n",
              " np.float32(0.3300483),\n",
              " np.float32(0.52876055),\n",
              " np.float32(0.49304804),\n",
              " np.float32(0.47443143),\n",
              " np.float32(0.49949452),\n",
              " np.float32(0.3559336),\n",
              " np.float32(0.46829256),\n",
              " np.float32(0.5981049),\n",
              " np.float32(0.31599212),\n",
              " np.float32(0.48948658),\n",
              " np.float32(0.6017874),\n",
              " np.float32(0.5373993),\n",
              " np.float32(0.3192425),\n",
              " np.float32(0.42395547),\n",
              " np.float32(0.35947332),\n",
              " np.float32(0.46397898),\n",
              " np.float32(0.2916767),\n",
              " np.float32(0.33634746),\n",
              " np.float32(0.27561527),\n",
              " np.float32(0.31319752),\n",
              " np.float32(0.34231946),\n",
              " np.float32(0.5086806),\n",
              " np.float32(0.3417511),\n",
              " np.float32(0.47043082),\n",
              " np.float32(0.28772196),\n",
              " np.float32(0.39965367),\n",
              " np.float32(0.5514742),\n",
              " np.float32(0.411646),\n",
              " np.float32(0.41458017),\n",
              " np.float32(0.4297628),\n",
              " np.float32(0.43498057),\n",
              " np.float32(0.3367395),\n",
              " np.float32(0.3182235),\n",
              " np.float32(0.64127874),\n",
              " np.float32(0.4496213),\n",
              " np.float32(0.40670815),\n",
              " np.float32(0.5524696),\n",
              " np.float32(0.5315816),\n",
              " np.float32(0.39938504),\n",
              " np.float32(0.44001886),\n",
              " np.float32(0.31058672),\n",
              " np.float32(0.39749077),\n",
              " np.float32(0.37293443),\n",
              " np.float32(0.43626857),\n",
              " np.float32(0.44758072),\n",
              " np.float32(0.43706414),\n",
              " np.float32(0.46611655),\n",
              " np.float32(0.49363834),\n",
              " np.float32(0.6898862),\n",
              " np.float32(0.40326327),\n",
              " np.float32(0.30513406),\n",
              " np.float32(0.43519086),\n",
              " np.float32(0.40617275),\n",
              " np.float32(0.57984483),\n",
              " np.float32(0.3450632),\n",
              " np.float32(0.454103),\n",
              " np.float32(0.31629217),\n",
              " np.float32(0.38879564),\n",
              " np.float32(0.45138872),\n",
              " np.float32(0.5845873),\n",
              " np.float32(0.44659686),\n",
              " np.float32(0.4283866),\n",
              " np.float32(0.5086364),\n",
              " np.float32(0.49563575),\n",
              " np.float32(0.48040187),\n",
              " np.float32(0.64957273),\n",
              " np.float32(0.7832873),\n",
              " np.float32(0.45693734),\n",
              " np.float32(0.25717294),\n",
              " np.float32(0.4074388),\n",
              " np.float32(0.2640239),\n",
              " np.float32(0.30277434),\n",
              " np.float32(0.3907417),\n",
              " np.float32(0.50180393),\n",
              " np.float32(0.5129273),\n",
              " np.float32(0.45037112),\n",
              " np.float32(0.44935355),\n",
              " np.float32(0.36517677),\n",
              " np.float32(0.49265003),\n",
              " np.float32(0.45120817),\n",
              " np.float32(0.30357766),\n",
              " np.float32(0.54436904),\n",
              " np.float32(0.37953243),\n",
              " np.float32(0.41590986),\n",
              " np.float32(0.4324815),\n",
              " np.float32(0.4107322),\n",
              " np.float32(0.517845),\n",
              " np.float32(0.34800372),\n",
              " np.float32(0.6359472),\n",
              " np.float32(0.36278847),\n",
              " np.float32(0.32859007),\n",
              " np.float32(0.3802314),\n",
              " np.float32(0.5214459),\n",
              " np.float32(0.63578415),\n",
              " np.float32(0.4727715),\n",
              " np.float32(0.6065633),\n",
              " np.float32(0.5111314),\n",
              " np.float32(0.40255332),\n",
              " np.float32(0.4544103),\n",
              " np.float32(0.41899422),\n",
              " np.float32(0.49778503),\n",
              " np.float32(0.51440364),\n",
              " np.float32(0.50223255),\n",
              " np.float32(0.45245388),\n",
              " np.float32(0.41059208),\n",
              " np.float32(0.45517367),\n",
              " np.float32(0.33724624),\n",
              " np.float32(0.61848557),\n",
              " np.float32(0.37585947),\n",
              " np.float32(0.33968204),\n",
              " np.float32(0.28624934),\n",
              " np.float32(0.3389164),\n",
              " np.float32(0.48687342),\n",
              " np.float32(0.48666996),\n",
              " np.float32(0.36633813),\n",
              " np.float32(0.6194854),\n",
              " np.float32(0.303145),\n",
              " np.float32(0.44719866),\n",
              " np.float32(0.30253807),\n",
              " np.float32(0.37985414),\n",
              " np.float32(0.74114054),\n",
              " np.float32(0.43110058),\n",
              " np.float32(0.32249838),\n",
              " np.float32(0.33810484),\n",
              " np.float32(0.505629),\n",
              " np.float32(0.4410223),\n",
              " np.float32(0.32591903),\n",
              " np.float32(0.36989117),\n",
              " np.float32(0.3629543),\n",
              " np.float32(0.3620368),\n",
              " np.float32(0.7797512),\n",
              " np.float32(0.5077363),\n",
              " np.float32(0.41053098),\n",
              " np.float32(0.29656693),\n",
              " np.float32(0.43829188),\n",
              " np.float32(0.35569376),\n",
              " np.float32(0.44599956),\n",
              " np.float32(0.39099678),\n",
              " np.float32(0.44261178),\n",
              " np.float32(0.56030756),\n",
              " np.float32(0.3660731),\n",
              " np.float32(0.4236311),\n",
              " np.float32(0.313276),\n",
              " np.float32(0.3550394),\n",
              " np.float32(0.33432138),\n",
              " np.float32(0.3978911),\n",
              " np.float32(0.4078474),\n",
              " np.float32(0.3986102),\n",
              " np.float32(0.2642559),\n",
              " np.float32(0.34612018),\n",
              " np.float32(0.48756525),\n",
              " np.float32(0.32646325),\n",
              " np.float32(0.31734052),\n",
              " np.float32(0.28116378),\n",
              " np.float32(0.31231737),\n",
              " np.float32(0.31253436),\n",
              " np.float32(0.5381073),\n",
              " np.float32(0.31220827),\n",
              " np.float32(0.34478134),\n",
              " np.float32(0.38409737),\n",
              " np.float32(0.33996886),\n",
              " np.float32(0.42545098),\n",
              " np.float32(0.38530493),\n",
              " np.float32(0.40237448),\n",
              " np.float32(0.41132793),\n",
              " np.float32(0.30095235),\n",
              " np.float32(0.38674098),\n",
              " np.float32(0.491886),\n",
              " np.float32(0.40411964),\n",
              " np.float32(0.3156846),\n",
              " np.float32(0.3347893),\n",
              " np.float32(0.15262005),\n",
              " np.float32(0.28009525),\n",
              " np.float32(0.31434047),\n",
              " np.float32(0.42423153),\n",
              " np.float32(0.6584158),\n",
              " np.float32(0.36081848),\n",
              " np.float32(0.30972695),\n",
              " np.float32(0.35353136),\n",
              " np.float32(0.49655974),\n",
              " np.float32(0.36828336),\n",
              " np.float32(0.32243755),\n",
              " np.float32(0.50360966),\n",
              " np.float32(0.27349943),\n",
              " np.float32(0.2804126),\n",
              " np.float32(0.34027252),\n",
              " np.float32(0.3881351),\n",
              " np.float32(0.31882295),\n",
              " np.float32(0.4386994),\n",
              " np.float32(0.39108443),\n",
              " np.float32(0.44852334),\n",
              " np.float32(0.36216262),\n",
              " np.float32(0.30334568),\n",
              " np.float32(0.42119548),\n",
              " np.float32(0.54537964),\n",
              " np.float32(0.50104856),\n",
              " np.float32(0.41839686),\n",
              " np.float32(0.39402267),\n",
              " np.float32(0.3379884),\n",
              " np.float32(0.36824948),\n",
              " np.float32(0.31720155),\n",
              " np.float32(0.2876732),\n",
              " np.float32(0.40859583),\n",
              " np.float32(0.37577382),\n",
              " np.float32(0.46000803),\n",
              " np.float32(0.55037665),\n",
              " np.float32(0.56869256),\n",
              " np.float32(0.5870572),\n",
              " np.float32(0.47386533),\n",
              " np.float32(0.35840362),\n",
              " np.float32(0.34677175),\n",
              " np.float32(0.4345584),\n",
              " np.float32(0.4314929),\n",
              " np.float32(0.318376),\n",
              " np.float32(0.37937146),\n",
              " np.float32(0.3117111),\n",
              " np.float32(0.42755586),\n",
              " np.float32(0.3483026),\n",
              " np.float32(0.36456403),\n",
              " np.float32(0.44987693),\n",
              " np.float32(0.34608176),\n",
              " np.float32(0.22610687),\n",
              " np.float32(0.33711976),\n",
              " np.float32(0.43776318),\n",
              " np.float32(0.3502253),\n",
              " np.float32(0.29596397),\n",
              " np.float32(0.30542716),\n",
              " np.float32(0.3822175),\n",
              " np.float32(0.4653796),\n",
              " np.float32(0.25084266),\n",
              " np.float32(0.2809939),\n",
              " np.float32(0.47251427),\n",
              " np.float32(0.30414486),\n",
              " np.float32(0.27662396),\n",
              " np.float32(0.37207285),\n",
              " np.float32(0.2821041),\n",
              " np.float32(0.58136827),\n",
              " np.float32(0.32566687),\n",
              " np.float32(0.38448438),\n",
              " np.float32(0.33984014),\n",
              " np.float32(0.26397437),\n",
              " np.float32(0.3495434)]"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_setup_tf(model, optimizer,loss_fn,train_data,teldic,engdic, n_batches=500, batch_size=32, max_char=30, device=device_gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-VuJ_7P3dY6",
        "outputId": "164efd25-75e3-46dd-a91c-c0c7230f25f0"
      },
      "outputs": [],
      "source": [
        "current_accuracy = calc_accuracy_tf(model, device=device_gpu)\n",
        "print(\"Test Accuracy:\" ,current_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JugMMFq1sevH"
      },
      "outputs": [],
      "source": [
        "\n",
        "best_accuracy = -1.0\n",
        "best_model_path = \"best_model_tf.weights.h5\"\n",
        "\n",
        "model = TransliterationEncoderDecoder(len(teldic), 256, len(engdic))\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False,reduction=None)\n",
        "for lr in [0.001]:\n",
        "    for batch_size in [32, 64]:\n",
        "        for n_batches in [500, , 200]:\n",
        "            expt_id = f\"{int(lr*100)}_{n_batches}_{batch_size}\"\n",
        "            train_setup_tf(model, optimizer,loss_fn,train_data,teldic,engdic, n_batches, batch_size, max_char=30, device=device_gpu)\n",
        "            current_accuracy = calc_accuracy_tf(model, device=device_gpu)\n",
        "\n",
        "            if current_accuracy > best_accuracy:\n",
        "                best_accuracy = current_accuracy\n",
        "\n",
        "                print(f\"New best model saved with accuracy: {best_accuracy:.2f}%\")\n",
        "\n",
        "            tf.keras.backend.clear_session()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "COKBk_tYXx8t",
        "outputId": "4132d390-6644-4044-b794-917e6f06089a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transliteration_encoder_decoder_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"transliteration_encoder_decoder_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ gru_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ ((<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">297,984</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>))                  │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ ((<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>))   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">591,360</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,453</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ gru_4 (\u001b[38;5;33mGRU\u001b[0m)                     │ ((\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;34m1\u001b[0m,     │       \u001b[38;5;34m297,984\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m256\u001b[0m))                  │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_5 (\u001b[38;5;33mGRU\u001b[0m)                     │ ((\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m))   │       \u001b[38;5;34m591,360\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m29\u001b[0m)             │         \u001b[38;5;34m7,453\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │        \u001b[38;5;34m65,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │        \u001b[38;5;34m65,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │           \u001b[38;5;34m257\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m7,680\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,036,318</span> (3.95 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,036,318\u001b[0m (3.95 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,036,318</span> (3.95 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,036,318\u001b[0m (3.95 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1nBvbfCp6tY"
      },
      "outputs": [],
      "source": [
        "def test_one_example(net, tel_input, tel_dic, eng_dic, max_char=30):\n",
        "    rev_eng_dic = {v: k for k, v in eng_dic.items()}\n",
        "\n",
        "    input_seq = word_rep_tf(tel_input, tel_dic)\n",
        "    output = net(input_seq, max_char=max_char, training=False)\n",
        "\n",
        "    pred_indices = tf.argmax(output, axis=2)[0].numpy()\n",
        "    pred_chars = [rev_eng_dic[i] for i in pred_indices]\n",
        "\n",
        "    if pred_chars and pred_chars[0] == '^':\n",
        "        pred_chars = pred_chars[1:]\n",
        "\n",
        "    if '$' in pred_chars:\n",
        "        stop_idx = pred_chars.index('$')\n",
        "        pred_chars = pred_chars[:stop_idx]\n",
        "\n",
        "    decoded = ''.join(pred_chars)\n",
        "    print(f\"Input: {tel_input} -> Predicted Output: {decoded}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oJ-Na8Fbb97",
        "outputId": "7fc17499-d864-4f30-bd73-f52c4456ad91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: ప్రతి -> Predicted Output: PRATI\n"
          ]
        }
      ],
      "source": [
        "test_one_example(model, \"ప్రతి\", teldic, engdic, max_char=30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pHk7Hj1b-3C",
        "outputId": "41b093a7-64e1-45a6-94ec-905ad755ad40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: పరమార్థం -> Predicted Output: PARAMARTHAM\n"
          ]
        }
      ],
      "source": [
        "test_one_example(model, \"పరమార్థం\", teldic, engdic, max_char=30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPAd-6dFp92q",
        "outputId": "e843d93a-fdbb-46f9-b857-39266873e80e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: ప్రతిబింబించటానికి -> Predicted Output: PRATIBINBINCHATINI\n"
          ]
        }
      ],
      "source": [
        "test_one_example(model, \"ప్రతిబింబించటానికి\", teldic, engdic, max_char=30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCf3yPa3dQh1"
      },
      "outputs": [],
      "source": [
        "def test_sentence_example(net, tel_sentence, tel_dic, eng_dic, max_char=30):\n",
        "    rev_eng_dic = {v: k for k, v in eng_dic.items()}\n",
        "\n",
        "    words = tel_sentence.strip().split()\n",
        "    decoded_words = []\n",
        "\n",
        "    for word in words:\n",
        "        input_seq = word_rep_tf(word, tel_dic)\n",
        "        output = net(input_seq, max_char=max_char, training=False)\n",
        "        pred_indices = tf.argmax(output, axis=2)[0].numpy()\n",
        "        pred_chars = [rev_eng_dic[i] for i in pred_indices]\n",
        "\n",
        "        if pred_chars and pred_chars[0] == '^':\n",
        "            pred_chars = pred_chars[1:]\n",
        "        if '$' in pred_chars:\n",
        "            pred_chars = pred_chars[:pred_chars.index('$')]\n",
        "\n",
        "        decoded_word = ''.join(pred_chars)\n",
        "        decoded_words.append(decoded_word)\n",
        "\n",
        "    decoded_sentence = ' '.join(decoded_words)\n",
        "    print(f\"Input: {tel_sentence}\")\n",
        "    print(f\"Predicted Output: {decoded_sentence}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWfmQ9itcaR4",
        "outputId": "645b6195-98ab-488c-e36f-2147fb31fe9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: దీన్ని ప్రయత్నించడానికి దిగువ మీ భాషను మరియు ఇన్‌పుట్ సాధనాన్ని ఎంచుకుని టైప్ చేయడాన్ని మొదలుపెట్టండి\n",
            "Predicted Output: DEENNI PRAYATNINCHADANI DIGUVA MEE BHASHANU MARIA INPUT SADHANANNI ENCHUKUNI TIPE CHEYADANNI MODALUPETTINDI\n"
          ]
        }
      ],
      "source": [
        "test_sentence_example(model, \"దీన్ని ప్రయత్నించడానికి దిగువ మీ భాషను మరియు ఇన్‌పుట్ సాధనాన్ని ఎంచుకుని టైప్ చేయడాన్ని మొదలుపెట్టండి\", teldic, engdic, max_char=30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAgbGf_qe9ci",
        "outputId": "2feabe36-b808-49e1-acf7-f11719e6c4cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: తెలుగు పదాలను ఇంగ్లీష్ అక్షరాలలోకి మార్పిడి చేసే ప్రాజెక్ట్\n",
            "Predicted Output: TELUGU PADALANU INGLISH AKSHARALAKOLI MARPIDI CHESE PRAJECT\n"
          ]
        }
      ],
      "source": [
        "test_sentence_example(model, \"తెలుగు పదాలను ఇంగ్లీష్ అక్షరాలలోకి మార్పిడి చేసే ప్రాజెక్ట్\", teldic, engdic, max_char=30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlPo-UMNhbyA",
        "outputId": "23483f75-3f0f-4864-f830-f4a32d97f062"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: ఈ ప్రాజెక్ట్ తెలుగు పదాలను శుద్ధంగా ఉచ్చరించేలా మారుస్తుంది\n",
            "Predicted Output: E PRAJECT TELUGU PADALANU SHUDDANGA UCHARINCHELA MARUSTUNDI\n"
          ]
        }
      ],
      "source": [
        "test_sentence_example(model, \"ఈ ప్రాజెక్ట్ తెలుగు పదాలను శుద్ధంగా ఉచ్చరించేలా మారుస్తుంది\", teldic, engdic, max_char=30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M97OmktWh4rJ",
        "outputId": "d0786809-ac71-4f1d-ea8d-54d2907c5076"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: పరిశోధనల ద్వారా అభివృద్ధి చెందిన ఈ యంత్రం ఖచ్చితమైన ఫలితాలు ఇస్తుంది\n",
            "Predicted Output: PARISHODHANALA DWARA ABHIVUDDHI CHENDINA E YANTRA KHACHITAMAINA FALITALU ISTUNDI\n"
          ]
        }
      ],
      "source": [
        "test_sentence_example(model, \"పరిశోధనల ద్వారా అభివృద్ధి చెందిన ఈ యంత్రం ఖచ్చితమైన ఫలితాలు ఇస్తుంది\", teldic, engdic, max_char=30)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "DxnoYqw2TVlq",
        "pxM5n8mq7EDJ"
      ],
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
