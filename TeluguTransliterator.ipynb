{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DxnoYqw2TVlq",
        "pxM5n8mq7EDJ"
      ],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMy6D1doMng6",
        "outputId": "0ffa364d-d6a2-4aa7-8f8e-840ec41c9b9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/CPU:0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import seaborn as sns\n",
        "import os, string, random, time, math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import clear_output\n",
        "import re\n",
        "import string\n",
        "import mlflow\n",
        "import mlflow.tensorflow\n",
        "\n",
        "# Device configuration (TensorFlow automatically handles GPU if available)\n",
        "device_gpu = \"/GPU:0\" if tf.config.list_physical_devices('GPU') else \"/CPU:0\"\n",
        "print(device_gpu)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(\"GPU Name:\", gpus[0].name)\n",
        "else:\n",
        "    print(\"No GPU found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbOzzYMqNtMB",
        "outputId": "acfbec28-975d-49c8-b33e-31018373cebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available: 0\n",
            "No GPU found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding"
      ],
      "metadata": {
        "id": "FXor2z4RN6iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "pad = '-PAD-'\n",
        "engdic = {pad : 0}\n",
        "for index ,alpha in enumerate(eng_alphabets):\n",
        "  engdic[alpha] = index+1\n",
        "print(engdic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX7iKp5BOLtM",
        "outputId": "61664e4a-43bc-40d2-af2a-7d9fea74a9f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Telugu unicode for hex range is 3072:3199\n",
        "tel_alphabets = [chr(alpha) for alpha in range(3072,3199)]\n",
        "tel_alphabets.append(chr(8204))\n",
        "tel_alphabets.append(chr(8205))\n",
        "tel_size = len(tel_alphabets)\n",
        "teldic = {pad : 0}\n",
        "for index ,alpha in enumerate(tel_alphabets):\n",
        "  teldic[alpha] = index+1\n",
        "print(teldic)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVzp945kOOZV",
        "outputId": "5cb2ddca-a7cb-4177-8d06-2f254e3e6da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'-PAD-': 0, 'ఀ': 1, 'ఁ': 2, 'ం': 3, 'ః': 4, 'ఄ': 5, 'అ': 6, 'ఆ': 7, 'ఇ': 8, 'ఈ': 9, 'ఉ': 10, 'ఊ': 11, 'ఋ': 12, 'ఌ': 13, '\\u0c0d': 14, 'ఎ': 15, 'ఏ': 16, 'ఐ': 17, '\\u0c11': 18, 'ఒ': 19, 'ఓ': 20, 'ఔ': 21, 'క': 22, 'ఖ': 23, 'గ': 24, 'ఘ': 25, 'ఙ': 26, 'చ': 27, 'ఛ': 28, 'జ': 29, 'ఝ': 30, 'ఞ': 31, 'ట': 32, 'ఠ': 33, 'డ': 34, 'ఢ': 35, 'ణ': 36, 'త': 37, 'థ': 38, 'ద': 39, 'ధ': 40, 'న': 41, '\\u0c29': 42, 'ప': 43, 'ఫ': 44, 'బ': 45, 'భ': 46, 'మ': 47, 'య': 48, 'ర': 49, 'ఱ': 50, 'ల': 51, 'ళ': 52, 'ఴ': 53, 'వ': 54, 'శ': 55, 'ష': 56, 'స': 57, 'హ': 58, '\\u0c3a': 59, '\\u0c3b': 60, '఼': 61, 'ఽ': 62, 'ా': 63, 'ి': 64, 'ీ': 65, 'ు': 66, 'ూ': 67, 'ృ': 68, 'ౄ': 69, '\\u0c45': 70, 'ె': 71, 'ే': 72, 'ై': 73, '\\u0c49': 74, 'ొ': 75, 'ో': 76, 'ౌ': 77, '్': 78, '\\u0c4e': 79, '\\u0c4f': 80, '\\u0c50': 81, '\\u0c51': 82, '\\u0c52': 83, '\\u0c53': 84, '\\u0c54': 85, 'ౕ': 86, 'ౖ': 87, '\\u0c57': 88, 'ౘ': 89, 'ౙ': 90, 'ౚ': 91, '\\u0c5b': 92, '\\u0c5c': 93, 'ౝ': 94, '\\u0c5e': 95, '\\u0c5f': 96, 'ౠ': 97, 'ౡ': 98, 'ౢ': 99, 'ౣ': 100, '\\u0c64': 101, '\\u0c65': 102, '౦': 103, '౧': 104, '౨': 105, '౩': 106, '౪': 107, '౫': 108, '౬': 109, '౭': 110, '౮': 111, '౯': 112, '\\u0c70': 113, '\\u0c71': 114, '\\u0c72': 115, '\\u0c73': 116, '\\u0c74': 117, '\\u0c75': 118, '\\u0c76': 119, '౷': 120, '౸': 121, '౹': 122, '౺': 123, '౻': 124, '౼': 125, '౽': 126, '౾': 127, '\\u200c': 128, '\\u200d': 129}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tel_alphabets[6]+tel_alphabets[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQ5Vr9F9OZuQ",
        "outputId": "1677c144-c1ad-4833-aad4-e2adb21b65cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ఆం\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### preprocessing"
      ],
      "metadata": {
        "id": "qyWbo3w4OdMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=[]\n",
        "Y=[]\n",
        "with open(r\"EngToTel.txt\",encoding = \"utf8\") as f:\n",
        "  for line in f:\n",
        "    line = line.split()\n",
        "    eng = line[0].strip().upper()\n",
        "    tel = line[1].strip()\n",
        "    X.append(eng)\n",
        "    Y.append(tel)"
      ],
      "metadata": {
        "id": "QrTfMlXPOjnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[1])\n",
        "print(Y[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwQQQZM7PNaQ",
        "outputId": "fd610675-7638-4e81-d91c-a2f13cfceb81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVATA\n",
            "దేవత\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def checkAdjChar(instring):\n",
        "    for i in range(0, len(instring)-2):\n",
        "        if (instring[i] == instring[i+1]):\n",
        "            return 1\n",
        "        else:\n",
        "            continue\n",
        "    return 0\n"
      ],
      "metadata": {
        "id": "b9Z1WMaGPe8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L=[]\n",
        "M=[]\n",
        "with open(r\"TelToEng.txt\",encoding = \"utf8\") as k:\n",
        "    for line in k:\n",
        "        line = line.split()\n",
        "        EN = line[1].strip().upper()\n",
        "        TE = line[0].strip()\n",
        "        if(len(TE)>10 and checkAdjChar(EN)==0):\n",
        "            L.append(EN)\n",
        "            M.append(TE)"
      ],
      "metadata": {
        "id": "-1oZice4QTlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(L[5])\n",
        "print(M[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydMVRvFCQcdz",
        "outputId": "8a876a9d-3b67-45ff-974c-1eb1811d6d3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANUMATINCHALEDU\n",
            "అనుమతించలేదు\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X+L\n",
        "Y = Y+M"
      ],
      "metadata": {
        "id": "Ioz29g9qROQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amPuM0XwRZZJ",
        "outputId": "0261cf8c-5e28-4ce1-cbb4-7628ceeed29b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)"
      ],
      "metadata": {
        "id": "fvC3OfZPRQBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training size:\",len(X_train))\n",
        "print(f\"Test size:\",len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Awen3MIrRfOE",
        "outputId": "f18c27fc-3d5e-450a-d6a2-ac25d6b4f009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training size: 12820\n",
            "Test size: 3206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "  print(X_train[i],Y_train[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeiQcks2RURD",
        "outputId": "ba359df5-9883-4c2b-9bd2-ee438cc910f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KUBJA కుబ్జ\n",
            "MAST మస్త్\n",
            "KALALU కలలు\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **dataloading**"
      ],
      "metadata": {
        "id": "J2RiLJOCSIQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TFDataloader:\n",
        "    def __init__(self, a, b):\n",
        "        self.tel_words, self.eng_words = a, b\n",
        "        self.shuffle_indices = list(range(len(self.tel_words)))\n",
        "        random.shuffle(self.shuffle_indices)\n",
        "        self.shuffle_start_index = 0\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tel_words)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.tel_words[idx], self.eng_words[idx]\n",
        "\n",
        "    def get_random_sample(self):\n",
        "        idx = np.random.randint(len(self.tel_words))\n",
        "        return self.__getitem__(idx)\n",
        "\n",
        "    def get_batch_from_array(self, batch_size, array):\n",
        "        end = self.shuffle_start_index + batch_size\n",
        "        batch = []\n",
        "        if end >= len(self.tel_words):\n",
        "            batch = [array[i] for i in self.shuffle_indices[0:end % len(self.tel_words)]]\n",
        "            end = len(self.tel_words)\n",
        "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index:end]]\n",
        "\n",
        "    def get_batch(self, batch_size, postprocess=True):\n",
        "        tel_batch = self.get_batch_from_array(batch_size, self.tel_words)\n",
        "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
        "        self.shuffle_start_index += batch_size\n",
        "\n",
        "        if self.shuffle_start_index >= len(self.tel_words):\n",
        "            random.shuffle(self.shuffle_indices)\n",
        "            self.shuffle_start_index = 0\n",
        "\n",
        "        return tel_batch, eng_batch\n",
        "\n",
        "    def to_tf_dataset(self, batch_size):\n",
        "        \"\"\"Convert to tf.data.Dataset for TensorFlow training\"\"\"\n",
        "        def batch_generator():\n",
        "            while True:\n",
        "                tel_batch, eng_batch = self.get_batch(batch_size)\n",
        "                for tel, eng in zip(tel_batch, eng_batch):\n",
        "                    yield tel, eng\n",
        "\n",
        "        dataset = tf.data.Dataset.from_generator(\n",
        "            batch_generator,\n",
        "            output_signature=(\n",
        "                tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "                tf.TensorSpec(shape=(), dtype=tf.string)\n",
        "            )\n",
        "        )\n",
        "        return dataset.batch(batch_size)\n"
      ],
      "metadata": {
        "id": "PydBxAE9LqgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Create dataloaders exactly like PyTorch\n",
        "train_data = TFDataloader(Y_train, X_train)\n",
        "test_data = TFDataloader(Y_test, X_test)\n",
        "\n",
        "print(type(test_data))\n",
        "\n",
        "    # This will produce the exact same output as your PyTorch version\n",
        "for i in range(3):\n",
        "    print(test_data[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8yWUbijSMUa",
        "outputId": "a20591b2-5817-4927-e76a-cc73a4e51ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.TFDataloader'>\n",
            "('వడ్లమూరు', 'VADLAMURU')\n",
            "('రాగంగళ్', 'RAAGANGAL')\n",
            "('కళ్యాణదుర్గం', 'KALYANDURG')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bss=train_data.get_batch(10)\n",
        "print(bss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loFOSXWQSZTv",
        "outputId": "ef196ff6-b1a0-4b8e-f60d-660c70ebfa70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['రాఫెల్', 'ఉప్పుగుండూరు', 'తిరునీర్మలై', 'గుర్రం', 'ప్లెసిస్', 'పుష్కరాలు', 'నెదర్లాండ్స్', 'కుక్క', 'డేల్', 'డీన్'], ['RAFAEL', 'UPPUGUNDUR', 'THIRUNEERMALAI', 'GURRAM', 'PLESSIS', 'PUSHKARAM', 'NETHERLANDS', 'KUKKA', 'DALE', 'DEAN'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def word_rep_tf(word, dic):\n",
        "    word = word.upper()\n",
        "    vocab_size = len(dic)\n",
        "    seq_len = len(word) + 1\n",
        "    one_hot = tf.zeros((seq_len, vocab_size), dtype=tf.float32)\n",
        "\n",
        "    for i, letter in enumerate(word):\n",
        "        pos = dic[letter]\n",
        "        one_hot = tf.tensor_scatter_nd_update(one_hot, [[i, pos]], [1.0])\n",
        "\n",
        "    pad_pos = dic[pad]\n",
        "    one_hot = tf.tensor_scatter_nd_update(one_hot, [[len(word), pad_pos]], [1.0])\n",
        "    return tf.expand_dims(one_hot, axis=0)  # Shape: (1, seq_len, vocab_size)\n"
      ],
      "metadata": {
        "id": "RI91aUu2S1Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gt_rep(word, dic, device='/CPU:0'):\n",
        "    word = word.upper()\n",
        "    with tf.device(device):\n",
        "        rep = tf.zeros([len(word) + 1, 1], dtype=tf.int64)\n",
        "\n",
        "        indices = []\n",
        "        updates = []\n",
        "\n",
        "        for letter_index, letter in enumerate(word):\n",
        "            pos = dic[letter]\n",
        "            indices.append([letter_index, 0])\n",
        "            updates.append(pos)\n",
        "\n",
        "        # Add padding at the end\n",
        "        indices.append([len(word), 0])\n",
        "        updates.append(dic[pad])\n",
        "\n",
        "        rep = tf.tensor_scatter_nd_update(rep, indices=indices, updates=updates)\n",
        "        rep = tf.reshape(rep, (1, -1))\n",
        "\n",
        "    return rep"
      ],
      "metadata": {
        "id": "SfTeEQ_2S5En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    print(Y[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg9lxjqeTCU5",
        "outputId": "a97ead57-d0e6-4657-a04f-8f4db4ac7b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "పంజాబీ\n",
            "దేవత\n",
            "బెషెవిస్\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=word_rep_tf(Y[0],teldic)\n",
        "\n",
        "print(a.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJ0RnftSMtUd",
        "outputId": "b82ee08f-00b6-49d5-b7d2-040f72e51686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 7, 130)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tel_batch, eng_batch = train_data.get_batch(32)\n",
        "for i in range(len(tel_batch)):\n",
        "  print(tel_batch[i],eng_batch[i])\n",
        "  input_seq = word_rep_tf(tel_batch[i], teldic)  # shape: (1, seq_len, tel_vocab_size)\n",
        "  gt_seq = gt_rep(eng_batch[i], engdic)\n",
        "  print(input_seq.shape)\n",
        "  print(gt_seq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udoMhi-NYpKH",
        "outputId": "059f7016-b9ce-483e-882f-5c0bbb58d4a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "హొరనాడు HORNADU\n",
            "(1, 8, 130)\n",
            "(1, 8)\n",
            "వీరులపాడు VEERULLAPADU\n",
            "(1, 10, 130)\n",
            "(1, 13)\n",
            "అవెంజర్స్ AVENGERS\n",
            "(1, 10, 130)\n",
            "(1, 9)\n",
            "వ్యవహరించేవారు VYAVAHARINCHAEVARU\n",
            "(1, 15, 130)\n",
            "(1, 19)\n",
            "లాప్లాస్ LAPLACES\n",
            "(1, 9, 130)\n",
            "(1, 9)\n",
            "సిటీస్ CITIES\n",
            "(1, 7, 130)\n",
            "(1, 7)\n",
            "బడేవారిపాలెం BADEVARIPALEM\n",
            "(1, 13, 130)\n",
            "(1, 14)\n",
            "రామాయణ్ RAMAYAN\n",
            "(1, 8, 130)\n",
            "(1, 8)\n",
            "రేస్క్యూయర్స్ RESCUERS\n",
            "(1, 14, 130)\n",
            "(1, 9)\n",
            "విన్స్ VINCE\n",
            "(1, 7, 130)\n",
            "(1, 6)\n",
            "అగర్వాల్ AGGARWAL\n",
            "(1, 9, 130)\n",
            "(1, 9)\n",
            "బావుంటుందని BAVUNTUNDANI\n",
            "(1, 12, 130)\n",
            "(1, 13)\n",
            "నయాపూల్ NAYAPUL\n",
            "(1, 8, 130)\n",
            "(1, 8)\n",
            "గాలికొదిలేశారంటూ GALIKODILESARANTU\n",
            "(1, 17, 130)\n",
            "(1, 18)\n",
            "మెటల్ METAL\n",
            "(1, 6, 130)\n",
            "(1, 6)\n",
            "లోరియస్ LORIUS\n",
            "(1, 8, 130)\n",
            "(1, 7)\n",
            "కొనసాగిందింది KONASAGINDINDI\n",
            "(1, 14, 130)\n",
            "(1, 15)\n",
            "చిన్న CHINNA\n",
            "(1, 6, 130)\n",
            "(1, 7)\n",
            "శిరోద్కర్ SHIRODKAR\n",
            "(1, 10, 130)\n",
            "(1, 10)\n",
            "లియొనార్డో LEONARDO\n",
            "(1, 11, 130)\n",
            "(1, 9)\n",
            "పర్యవసానాలను PARYAVASANALANU\n",
            "(1, 13, 130)\n",
            "(1, 16)\n",
            "ఆజ్ఞాపించిన AGNYAPINCHINA\n",
            "(1, 12, 130)\n",
            "(1, 14)\n",
            "నరస NARASA\n",
            "(1, 4, 130)\n",
            "(1, 7)\n",
            "ధామ్‌ DHAM\n",
            "(1, 6, 130)\n",
            "(1, 5)\n",
            "ప్రవేశించటానికి PRAVESINCHATANIKI\n",
            "(1, 16, 130)\n",
            "(1, 18)\n",
            "తిరుపతమ్మ TIRUPATAMMA\n",
            "(1, 10, 130)\n",
            "(1, 12)\n",
            "రైబోసోము RIBOSOME\n",
            "(1, 9, 130)\n",
            "(1, 9)\n",
            "ఈథర్ ETHER\n",
            "(1, 5, 130)\n",
            "(1, 6)\n",
            "బెంజిమన్ BENJAMIN\n",
            "(1, 9, 130)\n",
            "(1, 9)\n",
            "బభ్రువాహన BABRUVAHANA\n",
            "(1, 10, 130)\n",
            "(1, 12)\n",
            "చూసుకోవడంతోబాటు CHUSUKOVADAMTOBATU\n",
            "(1, 16, 130)\n",
            "(1, 19)\n",
            "డాక్టర్ DOCTOR\n",
            "(1, 8, 130)\n",
            "(1, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample2 = gt_rep(X[0],engdic)\n",
        "print(X[0])\n",
        "print(sample2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4O74rUiTOdy",
        "outputId": "4ac2818a-b599-4797-d692-c0496dd55504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PUNJABI\n",
            "tf.Tensor([[16 21 14 10  1  2  9  0]], shape=(1, 8), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GRU With Attention**"
      ],
      "metadata": {
        "id": "DxnoYqw2TVlq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransliterationEncoderDecoder(tf.keras.Model):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(TransliterationEncoderDecoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.encoder_rnn_cell = tf.keras.layers.GRU(hidden_size, return_sequences=True, return_state=True)\n",
        "        self.decoder_rnn_cell = tf.keras.layers.GRU(hidden_size, return_state=True)\n",
        "\n",
        "        self.h2o = tf.keras.layers.Dense(output_size, activation='softmax')\n",
        "        self.U = tf.keras.layers.Dense(hidden_size)\n",
        "        self.W = tf.keras.layers.Dense(hidden_size)\n",
        "        self.attn = tf.keras.layers.Dense(1)\n",
        "        self.out2hidden = tf.keras.layers.Dense(hidden_size)\n",
        "\n",
        "    def call(self, input_, max_char=30, gt=None,training=True):\n",
        "        batch_size = tf.shape(input_)[0]\n",
        "\n",
        "        # Encoder\n",
        "        eout, hidden = self.encoder_rnn_cell(input_)\n",
        "        #print(\"eout shape:\", eout.shape)\n",
        "        #print(\"encoder final hidden state shape:\", hidden.shape)\n",
        "\n",
        "        decoder_state = hidden\n",
        "        decoder_state = tf.reshape(decoder_state, (1,-1))\n",
        "\n",
        "        decoder_input = tf.zeros((batch_size, 1, self.output_size))  # Start with <SOS> one-hot\n",
        "        #print(\"initial decoder input shape:\", decoder_input.shape)\n",
        "\n",
        "        outputs = []\n",
        "\n",
        "        U = self.U(eout)\n",
        "        #print(\"U shape:\", U.shape)\n",
        "\n",
        "        for i in range(max_char):\n",
        "            W = self.W(decoder_state)\n",
        "            #print(f\"\\nTime Step {i+1}:\")\n",
        "            #print(\"W (before expand) shape:\", W.shape)\n",
        "            W = tf.expand_dims(W, 1)\n",
        "            #print(\"W shape:\", W.shape)\n",
        "\n",
        "            attn_input = tf.nn.tanh(U + W)\n",
        "            #print(\"attention input shape (U + W):\", attn_input.shape)\n",
        "\n",
        "            V = self.attn(attn_input)\n",
        "            #print(\"V shape:\", V.shape)\n",
        "\n",
        "            attn_weights = tf.nn.softmax(V, axis=1)\n",
        "            #print(\"attention weights shape:\", attn_weights.shape)\n",
        "\n",
        "            attn_applied = tf.reduce_sum(attn_weights * eout, axis=1, keepdims=True)\n",
        "            #print(\"attention applied shape:\", attn_applied.shape)\n",
        "\n",
        "            embedded = self.out2hidden(decoder_input)\n",
        "            #print(\"embedded decoder input shape:\", embedded.shape)\n",
        "\n",
        "            decoder_input_concat = tf.concat([embedded, attn_applied], axis=-1)\n",
        "            #print(\"concatenated decoder input shape:\", decoder_input_concat.shape)\n",
        "\n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input_concat, initial_state=decoder_state)\n",
        "            decoder_state = tf.reshape(decoder_state, (1,-1))\n",
        "            #print(\"decoder GRU output shape:\", out.shape)\n",
        "            #print(\"decoder new state shape:\", decoder_state.shape)\n",
        "\n",
        "            out = self.h2o(tf.expand_dims(out, axis=1))\n",
        "            #print(\"output after final dense + softmax shape:\", out.shape)\n",
        "\n",
        "            outputs.append(out[:, 0, :])\n",
        "            #print(\"appended output shape:\", outputs[-1].shape)\n",
        "            # gt = tf.reshape(gt, (batch_size, max_char))\n",
        "            # print(gt.shape)\n",
        "            # print(gt)\n",
        "            idx = tf.argmax(out, axis=2, output_type=tf.int32)\n",
        "\n",
        "            if training and gt is not None:\n",
        "                # Use ground truth index at timestep `i`\n",
        "                idx = tf.expand_dims(gt[:, i], axis=1)\n",
        "            # One-hot encode\n",
        "            one_hot = tf.one_hot(idx, depth=self.output_size)\n",
        "\n",
        "            # Detach (not needed in TF for one-hot because it's non-trainable input, but for symmetry):\n",
        "            decoder_input = tf.stop_gradient(one_hot)\n",
        "\n",
        "        final_output = tf.stack(outputs, axis=1)\n",
        "        #print(\"final stacked output shape:\", final_output.shape)\n",
        "        return final_output\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bpk8OeJMTaKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = TransliterationEncoderDecoder(len(teldic),256,len(engdic))\n"
      ],
      "metadata": {
        "id": "tURA_UluXoEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def infer(model, name, n, device='/CPU:0'):\n",
        "    with tf.device(device):\n",
        "        # word_rep_tf now returns [1, seq_len, vocab_size]\n",
        "        name_ohe = word_rep_tf(name, teldic)\n",
        "\n",
        "        # Call the model\n",
        "        # Model returns [max_char, batch_size, output_size]\n",
        "        output_batch = model(name_ohe, max_char=n,training=False)\n",
        "\n",
        "        # Assuming batch size is 1 for inference, take the first (and only) element\n",
        "        # output_single shape: [max_char, output_size]\n",
        "        output_single = output_batch[:, 0, :]\n",
        "\n",
        "        return output_single"
      ],
      "metadata": {
        "id": "kVf67QOaTwGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OtVjLTNwUUi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training**"
      ],
      "metadata": {
        "id": "pxM5n8mq7EDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_batch_tf(model, optimizer, loss_fn, tel_batch, eng_batch, teldic, engdic, max_char, device=\"/CPU:0\"):\n",
        "    with tf.device(device):\n",
        "        batch_size = len(tel_batch)\n",
        "        total_loss = 0\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            input_seq = word_rep_tf(tel_batch[i], teldic)  # shape: (1, seq_len, tel_vocab_size)\n",
        "            gt_seq = gt_rep(eng_batch[i], engdic)\n",
        "            gt_without_squeze=gt_seq     # shape: (1, target_len)\n",
        "            # print(gt_seq)\n",
        "            # Squeeze the gt_seq to remove the batch dimension\n",
        "            gt_seq = tf.squeeze(gt_seq, axis=0)  # shape: (target_len,)\n",
        "            # print(gt_seq)\n",
        "\n",
        "            # print(\"inputshape\",input_seq.shape)\n",
        "            # print(\"gtshape:\",gt_seq.shape)\n",
        "\n",
        "            max_char = tf.shape(gt_seq)[0]\n",
        "            with tf.GradientTape() as tape:\n",
        "                output = model(input_seq, max_char=max_char,gt=gt_without_squeze)  # shape: (1, max_char, eng_vocab_size)\n",
        "                # print(output)\n",
        "                output = output[0]  # shape: (max_char, eng_vocab_size)\n",
        "\n",
        "                loss = 0\n",
        "\n",
        "                for t in range(tf.shape(gt_seq)[0]):\n",
        "                    token_loss = loss_fn(gt_seq[t], output[t])  # Compare each ground truth token with predicted logits\n",
        "                    loss += token_loss\n",
        "                loss = loss / tf.cast(tf.shape(gt_seq)[0], tf.float32)\n",
        "            grads = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "            total_loss += loss.numpy()\n",
        "\n",
        "        return total_loss / batch_size\n"
      ],
      "metadata": {
        "id": "bxzW0S2G7Hlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_setup_tf(model, optimizer, loss_fn, dataset, teldic, engdic, n_batches=100, batch_size=10, max_char=20, device=\"/CPU:0\"):\n",
        "    loss_arr = []\n",
        "\n",
        "    for i in range(n_batches):\n",
        "        tel_batch, eng_batch = dataset.get_batch(batch_size)\n",
        "        #print(\"hi in tsetip\")\n",
        "        loss = train_batch_tf(model, optimizer, loss_fn, tel_batch, eng_batch, teldic, engdic, max_char, device=device)\n",
        "        loss_arr.append(loss)\n",
        "\n",
        "        if True:\n",
        "            print(f\"Iteration {i}, Loss: {loss:.4f}\")\n",
        "            plt.plot(loss_arr, '-*')\n",
        "            plt.xlabel(\"Iteration\")\n",
        "            plt.ylabel(\"Loss\")\n",
        "            plt.show()\n",
        "            clear_output(wait=True)\n",
        "\n",
        "    return loss_arr\n"
      ],
      "metadata": {
        "id": "0h5fDcYL7_oJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy_tf(model, device='/CPU:0'):\n",
        "    predictions = []\n",
        "    accuracy = 0.0\n",
        "\n",
        "    with tf.device(device):\n",
        "        for i in range(len(test_data)):\n",
        "            tel, eng = test_data[i]\n",
        "            gt = gt_rep(eng, engdic, device)  # Shape: (seq_len, 1)\n",
        "\n",
        "            outputs = infer(model, tel, gt.shape[0], device=device)  # List of tensors, shape [1, 1, vocab_size] each\n",
        "            correct = 0\n",
        "\n",
        "            for index, out in enumerate(outputs):\n",
        "                # Adjust indexing to handle potential scalar or [1,1] shape from argmax\n",
        "                pred_index = tf.argmax(out, axis=-1).numpy().flatten()[0]  # Predicted class\n",
        "                true_index = gt[index][0].numpy()                   # Ground truth class\n",
        "\n",
        "                if pred_index == true_index:\n",
        "                    correct += 1\n",
        "\n",
        "            accuracy += correct / gt.shape[0]\n",
        "\n",
        "        accuracy /= len(test_data)\n",
        "        accuracy *= 100\n",
        "\n",
        "        # mlflow.log_metric('test_accuracy', accuracy) # Commenting out MLflow for now\n",
        "        print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "        return accuracy"
      ],
      "metadata": {
        "id": "7VKkMKAmWqBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calc_accuracy_tf(model=model_tf)"
      ],
      "metadata": {
        "id": "JfLV7x6gWtGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W9NmWUwSsdxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# import numpy as np\n",
        "# import os\n",
        "\n",
        "best_accuracy = -1.0\n",
        "best_model_path = \"best_model_tf.weights.h5\"\n",
        "  # Create a new model\n",
        "model = TransliterationEncoderDecoder(len(teldic), 256, len(engdic))\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False,reduction=None)\n",
        "for lr in [0.001]:\n",
        "    for batch_size in [32, 64]:\n",
        "        for n_batches in [100, 150, 200]:\n",
        "            expt_id = f\"{int(lr*100)}_{n_batches}_{batch_size}\"\n",
        "\n",
        "            # Train model\n",
        "            train_setup_tf(model, optimizer,loss_fn,train_data,teldic,engdic, n_batches, batch_size, max_char=30, device=device_gpu)\n",
        "\n",
        "            # Evaluate model\n",
        "            current_accuracy = calc_accuracy_tf(model, device=device_gpu)\n",
        "\n",
        "            # Check and save the best model\n",
        "            if current_accuracy > best_accuracy:\n",
        "                best_accuracy = current_accuracy\n",
        "\n",
        "                print(f\"New best model saved with accuracy: {best_accuracy:.2f}%\")\n",
        "\n",
        "            # Clear memory\n",
        "            tf.keras.backend.clear_session()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "JugMMFq1sevH",
        "outputId": "cc361d1f-2a55-466f-9e1e-bbe6d286951c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 92.11%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'>' not supported between instances of 'NoneType' and 'float'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-607232207>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# Check and save the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mcurrent_accuracy\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_accuracy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0mbest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'NoneType' and 'float'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "COKBk_tYXx8t",
        "outputId": "99adf582-6583-4371-c0b8-85faa6ca51b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"transliteration_encoder_decoder_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transliteration_encoder_decoder_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ gru_6 (\u001b[38;5;33mGRU\u001b[0m)                     │ ((\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;34m1\u001b[0m,      │       \u001b[38;5;34m297,984\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m256\u001b[0m))                  │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_7 (\u001b[38;5;33mGRU\u001b[0m)                     │ ((\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m))   │       \u001b[38;5;34m591,360\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m27\u001b[0m)             │         \u001b[38;5;34m6,939\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │        \u001b[38;5;34m65,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m7,168\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ gru_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ ((<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">297,984</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>))                  │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ ((<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>))   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">591,360</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,939</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,168</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,035,292\u001b[0m (3.95 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,035,292</span> (3.95 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,035,292\u001b[0m (3.95 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,035,292</span> (3.95 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_one_example(net, tel_input, tel_dic, eng_dic, max_char=30):\n",
        "    rev_eng_dic = {v: k for k, v in eng_dic.items()}\n",
        "\n",
        "    input_seq = word_rep_tf(tel_input, tel_dic)  # shape: (seq_len, input_size)\n",
        "    # input_seq = tf.expand_dims(input_seq, axis=0)  # shape: (1, seq_len, input_size)\n",
        "\n",
        "    output = net(input_seq, max_char=max_char, training=False)  # shape: (1, max_char, vocab_size)\n",
        "\n",
        "    pred_indices = tf.argmax(output, axis=2)[0].numpy()  # (max_char,)\n",
        "    pred_chars = [idx for idx in pred_indices if idx != eng_dic['-PAD-']]  # Assuming you have '<pad>' in vocab\n",
        "    decoded = ''.join([rev_eng_dic[i] for i in pred_chars])\n",
        "\n",
        "    print(f\"Input: {tel_input} -> Predicted Output: {decoded}\")\n"
      ],
      "metadata": {
        "id": "K1nBvbfCp6tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_one_example(model, \"ప్రతిబింబించటానికి\", teldic, engdic, max_char=30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPAd-6dFp92q",
        "outputId": "b67f690e-dd7b-4be4-9445-22a6e77b2088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: ప్రతిబింబించటానికి -> Predicted Output: PRATIBINCHANICHANIINCHINCH\n"
          ]
        }
      ]
    }
  ]
}